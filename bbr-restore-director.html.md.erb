---
title: Restoring the PKS BOSH Director
owner: PKS
---

<strong><%= modified_date %></strong>

This topic describes how to use BOSH Backup and Restore (BBR) to restore the PKS BOSH Director.

To back up the PKS BOSH Director plane with BBR, see [Backing up the PKS BOSH Director](bbr-backup-director.html).

## <a id="recreate-vms"></a> Recreate the BOSH Director VM

In the event of losing your BOSH Director or Ops Manager environment, you must recreate the BOSH Director VM before restoring the PKS BOSH Director.

In a disaster recovery scenario, you can re-create the BOSH Director with your <%= vars.product_short %> Ops Manager Installation settings generated in [Exporting Installation Settings](bbr-backup-director.html#export-opsman-settings).

To redeploy and reconfigure your Ops Manager environment and spin up a new PKS BOSH Director, run the following steps:

  1. [Step 1: Deploy Ops Manager](#deploy-opsmanager).
  1. [Step 2: Import Installation Settings](#import-settings).
  1. [Step 3: (Optional) Configure Ops Manager for New Resources](#config-new-resources).
  1. [Step 4: Remove BOSH State File](#bosh-state).
  1. [Step 5: Deploy the BOSH Director](#bosh-only-deploy).
  1. [Step 6: Transfer Artifacts to Jumpbox](#artifacts-jumpbox).

<p class="note"><strong>Note</strong>: A change in VM size or underlying hardware should not affect the ability for BBR restore data, as long as adequate storage space to restore the data exists.</p>

### <a id='deploy-opsmanager'></a> Step 1: Deploy Ops Manager

In an event of a disaster, you may lose not only your VMs and disks, but your IaaS resources as well, such as networks and load balancers.

If you need to recreate your IaaS resources, prepare your environment for PCF by following the instructions specific to your IaaS in [Installing <%= vars.product_short %>](installing.html).

If you recreate your IaaS resources, you must also add those resources to Ops Manager by performing the procedures in the [Step 3: (Optional) Configure Ops Manager for New Resources](#config-new-resources) section.

### <a id='import-settings'></a>Step 2: Installation Settings

Import your installation settings. This can be done in two ways:

  1. Using the Ops Manager UI

      1. Access your new Ops Manager by navigating to `YOUR-OPS-MAN-FQDN` in a browser.

      1. On the **Welcome to Ops Manager** page, click **Import Existing Installation**.

      1. In the import panel, perform the following tasks:
        * Enter the **Decryption Passphrase** in use when you exported the installation settings from Ops Manager.
        * Click **Choose File** and browse to the installation zip file that you exported in [Exporting Installation Settings](bbr-backup-director.html#export-opsman-settings).

      1. Click **Import**.
      <p class="note">
      <strong>Note:</strong> Some browsers do not provide feedback on the status of the import process, and may appear to hang.
      The import process takes at least 10 minutes, and takes longer the more tiles that were present on the backed-up Ops Manager.
      </p>

      1. A **Successfully imported installation** message appears upon completion.

  1. Using the Ops Manager API:

      ```
      curl "https://OPS-MAN-FQDN/api/v1/installation_asset_collection \
        -X POST \
        -H "Authorization: Bearer UAA-ACCESS-TOKEN" \
        -F 'installation[file]=@installation.zip' \
        -F 'passphrase=DECRYPTION-PASSPHRASE'
      ```

      Where:
      - `OPS-MAN-FQDN` is the fully-qualified domain name (FQDN) for your Ops Manager deployment.
      - `UAA-ACCESS-TOKEN` is the UAA access token. For more information about how to retrieve this token, see [Using the Ops Manager API](https://docs.pivotal.io/pivotalcf/customizing/ops-man-api.html).
      - `DECRYPTION-PASSPHRASE` is the decryption passphrase in use when you exported the installation settings from Ops Manager.

      <p class="note warning">
      <strong>WARNING:</strong> Do not click <strong>Apply Changes</strong> in Ops Manager until the instruction in Step 14: Redeploy PAS.
      </p>

### <a id="config-new-resources"></a> Step 3: (Optional) Configure Ops Manager for New Resources

If you recreated IaaS resources such as networks and load balancers by following the steps in the [Deploy Ops Manager](#deploy-opsmanager) section above, perform the following steps to update Ops Manager with your new resources:

1. Enable Ops Manager advanced mode. For more information, see [How to Enable Advanced Mode in the Ops Manager](https://community.pivotal.io/s/article/How-to-Enable-Advanced-Mode-in-the-Ops-Manager) in the Pivotal Knowledge Base.
  <p class="note">
  <strong>Note:</strong> In advanced mode Ops Manager will allow you to make changes that are normally disabled. You may see warning messages when you save changes.
  </p>

1. Navigate to the Ops Manager Installation Dashboard and click the BOSH Director tile.

1. If you are using Google Cloud Platform (GCP), click **Google Config** and update:
    1. **Project ID** to reflect the GCP project ID.
    1. **Default Deployment Tag** to reflect the environment name.
    1. **AuthJSON** to reflect the service account.

1. Click **Create Networks** and update the network names to reflect the network names for the new environment.

1. If your BOSH Director had an external hostname, you must change it in **Director Config > Director Hostname** to ensure it does not conflict with the hostname of the backed up Director.

1. Ensure that there are no outstanding warning messages in the BOSH Director tile, then disable Ops Manager advanced mode. For more information, see [How to Enable Advanced Mode in the Ops Manager](https://community.pivotal.io/s/article/How-to-Enable-Advanced-Mode-in-the-Ops-Manager) in the Pivotal Knowledge Base.

### <a id="bosh-state"></a> Step 4: Remove BOSH State File

1. SSH into your Ops Manager VM. For more information, see the [SSH into Ops Manager](https://docs.pivotal.io/pivotalcf/customizing/trouble-advanced.html#ssh) section of the _Advanced Troubleshooting with the BOSH CLI_ topic.

1. To delete the `/var/tempest/workspaces/default/deployments/bosh-state.json` file, run the following on the Ops Manager VM:

    ```
    sudo rm /var/tempest/workspaces/default/deployments/bosh-state.json
    ```

1. In a browser, navigate to your Ops Manager's fully-qualified domain name.
1. Log in to Ops Manager.

### <a id="bosh-only-deploy"></a> Step 5: Deploy the BOSH Director

Use the Ops Manager API or the checkbox on the **Review Pending Changes** page to deploy the BOSH Director by itself.

### <a id="artifacts-jumpbox"></a> Step 6: Transfer Artifacts to Jumpbox

Previously, you moved the TAR and metadata files of the backup artifacts off your jumpbox to your preferred storage space. Now you must transfer those files back to your jumpbox.
For more information on how to do this, see [Step 2: Transfer Artifacts to Jumpbox](bbr-restore-control-plane.html#artifacts-jumpbox) section of the _Restoring the PKS Control Plane_ topic.

## <a id='restore'></a> Restore the Enterprise PKS BOSH Director

<p class="note"><strong>Note</strong>: The BBR restore command can take a long time to complete.
You can run it independently of the SSH session so that the process can continue running even if
your connection to the jumpbox fails. The command above uses <code>nohup</code>, but you run the
command in a <code>screen</code> or <code>tmux</code> session instead.</p>

Perform the following steps to restore the PKS BOSH Director. You run these commands on your jumpbox.  You can use the optional `--debug` flag to enable debug logs. See the [BBR Logging](bbr-logging.html) topic for more information.

1. Ensure the <%= vars.product_short %> BOSH Director backup artifact is in the folder from which you run BBR.

1. Run the BBR restore command to restore the PKS BOSH Director:

    ```
    nohup bbr director \
    --host BOSH-DIRECTOR-IP \
    --username bbr \
    --private-key-path PRIVATE-KEY-FILE \
    restore \
    --artifact-path PATH-TO-DIRECTOR-BACKUP
    ```

    Replace the placeholder values as follows:
    <table>
      <tr>
        <th width="32%">Credential</th>
        <th>Location</th>
      </tr>
      <tr>
        <td><code>BOSH-DIRECTOR-IP</code></td>
        <td>This is the address of the BOSH Director. If the BOSH Director is public, BOSH-DIRECTOR-IP is a URL, such as `https://my-bosh.xxx.cf-app.com`. Otherwise, this is the internal IP `BOSH-DIRECTOR-IP` which you can retrieve as show in [Retrieve BOSH Director Address](bbr-backup-director.html#retrieve-bosh-address).</td>
      </tr>
      <tr>
        <td><code>PRIVATE-KEY-FILE</code></td>
        <td>This is the path to the private key file that you can create from `Bbr Ssh Credentials` as shown in [Download the BBR SSH Credentials](bbr-backup-director.html#bbr-ssh-creds).</td>
      </tr>
      <tr>
        <td><code>PATH-TO-DEPLOYMENT-BACKUP</code></td>
        <td>Use the path to the PKS BOSH Director backup that you want to restore.</td>
      </tr>
    </table>
    <br>
    For example:

    <pre class="terminal">
    $ nohup bbr director \
    --target 10.0.0.5 \
    --username bbr \
    --private-key-path private.pem \
    restore \
    --artifact-path /home/10.0.0.5-abcd1234abcd1234
    </pre>

    If the command fails, follow the steps in [Recover from a Failing Command](#recover-from-failing-command).

1. Delete old disk references in the BOSH Director database by running the following command:

    ```
    bosh cloud-check
    ```

    If the `bosh cloud-check` command does not successfully delete disk references, and you see a message similar to the following, perform the additional procedures in the [Remove Unused Disks](https://docs.pivotal.io/pivotalcf/customizing/backup-restore/restore-pcf-bbr.html#removing-disks).


    <pre class="terminal">
    Scanning 19 persistent disks: 19 OK, 0 missing ...
    </pre>


## <a id="recover-from-failing-command"></a>Recover from a Failing Command

1. Ensure that you set all the parameters in the command.
1. Ensure that the BOSH Director credentials are valid.
1. Ensure that the jumpbox can reach the BOSH Director.
1. Ensure the source BOSH Director backup is compatible with the target BOSH Director.
1. If you see the error message `Directory /var/vcap/store/bbr-backup already exists on instance`,
run the relevant commands from the [Clean up After Failed Restore](#manual-clean) section of this
topic.
1. See the [BBR Logging](bbr-logging.html) topic.

## <a id='cancel-restore'></a>Cancel a Restore

If you must cancel a restore, perform the following steps:

1. Terminate the BBR process by pressing Ctrl-C and typing `yes` to confirm.
1. Perform the procedures in the [Clean up After Failed Restore](#manual-clean) section to enable future restores. Stopping a restore can leave the system in an unusable state and prevent future restores.

## <a id="manual-clean"></a>Clean up After Failed Restore

If your restore process fails, then the process may leave the BBR restore folder on the instance. As a result, any subsequent restore attempts may also fail. In addition, BBR may not have run the post-restore scripts, which can leave the instance in a locked state.

To resolve these issues, run the BBR cleanup script with the following command:

  ```
  nohup bbr director \
  --host BOSH-DIRECTOR-IP \
  --username bbr \
  --private-key-path PRIVATE-KEY-FILE \
  restore-cleanup
  ```

  Replace the placeholder values as follows:
  <table>
    <tr>
      <th width="32%">Credential</th>
      <th>Location</th>
    </tr>
    <tr>
      <td><code>BOSH-DIRECTOR-IP</code></td>
      <td>This is the address of the BOSH Director. If the BOSH Director is public, BOSH-DIRECTOR-IP is a URL, such as `https://my-bosh.xxx.cf-app.com`. Otherwise, this is the internal IP `BOSH-DIRECTOR-IP` which you can retrieve as show in [Retrieve BOSH Director Address](bbr-backup-director.html#retrieve-bosh-address).</td>
    </tr>
    <tr>
      <td><code>PRIVATE-KEY-FILE</code></td>
      <td>This is the path to the private key file that you can create from `Bbr Ssh Credentials` as shown in [Download the BBR SSH Credentials](bbr-backup-director.html#bbr-ssh-creds).</td>
    </tr>
  </table>
<br>
  For example:

  <pre class="terminal">
  $ nohup bbr director \
  --target 10.0.0.5 \
  --username bbr \
  --private-key-path private.pem \
  restore-cleanup
  </pre>
