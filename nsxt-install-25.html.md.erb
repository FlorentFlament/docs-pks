---
title: Installing and Configuring NSX-T v2.5.x for Enterprise PKS
owner: PKS-NSXT
---

<strong><%= modified_date %></strong>

This topic provides instructions for installing NSX-T v2.5.x for use with <%= vars.product_full %> on vSphere.

##<a id='nsxt-24-prereqs'></a> Prerequisites

Before you begin this procedure, ensure that you have successfully completed all preceding steps for installing <%= vars.product_short %> on vSphere with NSX-T, including:

<ul>
  <li>
    <a href="./vsphere-nsxt-requirements.html">vSphere with NSX-T Version Requirements</a>
  </li>
  <li>
    <a href="./vsphere-nsxt-rpd-mpd.html">Hardware Requirements for <%= vars.product_short %> on vSphere with NSX-T</a>
  </li>
  <li>
    <a href="./nsxt-topologies.html">NSX-T Deployment Topologies for <%= vars.product_short %></a>
  </li>
  <li>
    <a href="./nsxt-prepare-env.html">Preparing to Deploy <%= vars.product_short %> with NSX-T on vSphere</a>
  </li>
  <li>
    <a href="./nsxt-deploy-24.html">Considerations for Deploying NSX-T v2.4 for <%= vars.product_short %> on vSphere</a>
  </li>
</ul>

##<a id='nsxt-25-install'></a> Installing NSX-T v2.5.x

To perform a new installation of NSX-T v2.5.x for <%= vars.product_short %>, complete the following steps.

###<a id='nsx-install-prepare'></a> Step 1: Prepare for Installing NSX-T v2.5.x

[Prepare for Installing NSX-T v2.5](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-EC9633E5-3CF1-433B-B7B5-FC9BBB3EE8F0.html).

###<a id='nsx-install-mgmt-cluster'></a> Step 2: Deploy NSX-T Manager Appliances and Configure the NSX-T Management Cluster

1. [Install the NSX Manager Unified Appliance for Enterprise PKS](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-FA0ABBBD-34D8-4DA9-882D-085E7E0D269E.html) using the OVA file, for example: `nsx-unified-appliance-2.4.1.0.0.13716579.ova`.

1. [Log In to the Newly Created NSX Manager](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-BF9FF9E2-47BD-466F-BDD2-8FF5145412E5.html).

1. [Add a Compute Manager](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-D225CAFC-04D4-44A7-9A09-7C365AAFCA0E.html).

1. [Deploy Two Additional NSX Manager Nodes to Form a NSX Management Cluster](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-B89F5831-62E4-4841-BFE2-3F06542D5BF5.html) Using the NSX Manager UI.

1. [Configure a Virtual IP Address and Cluster Certificate for the NSX v2.4 Management Cluster](./nsxt-mgmt-vip.html). Alternatively, [Provision a Load Balancer for the NSX-T v2.4 Management Cluster](./nsxt-mgmt-lb.html).
	
<p class="note"><strong>Note:</strong> If you do not require scalability, configure a Cluster VIP to achieve HA for the NSX-T Management Cluster. If you need to scale, provision a load balancer for the NSX-T Management Cluster.</p>

<p class="note"><strong>Note:</strong> To provision a load balancer, you will first need to deploy and configure NSX-T Edge Nodes.</p>

###<a id='nsx-install-edges'></a> Step 3: Deploy NSX Edge Nodes and Join Them with the Management Plane

NSX-T Edge Nodes run load balancers for <%= vars.product_short %> API traffic, load balancer services for Kubenetes pods, and ingress controllers for Kubernetes pods.

<%= vars.product_short %> supports active/standby Edge Node failover and requires at least two Edge Nodes. In addition, <%= vars.product_short %> requires the Edge Node Large VM (8 vCPU, 16 GB of RAM, and 120 GB of storage). The default size of the LB provisioned for <%= vars.product_short %> is small. You can customize this after deploying <%= vars.product_short %> using <a href="network-profiles.html">Network Profiles</a>.

1. [Install One or More Pair of NSX Edge Nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-AECC66D0-C968-4EF2-9CAD-7772B0245BF6.html) using the OVA file, for example: `nsx-edge-2.4.1.0.0.13716583.ova`.

<p class="note"><strong>Warning:</strong> For Enterprise PKS you must install a large size VM form factor or the bare metal Edge Node.</p>

1. [Join Each NSX Edge Node with the Management Plane](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-11BB4CF9-BC1D-4A76-A32A-AD4C98CBF25B.html).

The table below lists the maximum number of load balancers per Edge Node form factor.

Edge Node Type  | LB Small Max  | LB Medium Max | LB Large Max  | Supported by <%= vars.product_short %>
----------------|---------------|---------------|---------------|-----------------
Edge VM Small   | 0             | 0             | 0        		| No
Edge VM Medium  | 1             | 0             | 0        		| No
Edge VM Large   | 40            | 4             | 0        		| Yes
Edge Bare Metal | 750           | 100           | 7        		| Yes

Keep in mind the following requirements for NSX Edge Nodes with <%= vars.product_short %>:

* <%= vars.product_short %> requires the NSX-T Edge Node large VM (8 vCPU and 16 GB of RAM) or the bare metal Edge Node. For more information, see <a href="./vsphere-nsxt-rpd-mpd.html">Hardware requirements for <%= vars.product_short %> on vSphere with NSX-T</a>.
* The default load balancer deployed by NSX-T for an <%= vars.product_short %>-provisioned Kubernetes cluster is the small load balancer. The size of the load balancer can be customized using <a href="./network-profiles-define.html">Network Profiles</a>.
* Edge Node VMs can only be deployed on Intel-based ESXi hosts.
* The large load balancer requires a bare metal Edge Node.
* For high-availability Edge Nodes are deployed as pairs within an Edge Cluster. The minimum number of Edge Nodes per Edge Cluster is 2; the maximum is 10. <%= vars.product_short %> supports active/standby mode only. In standby mode, the standby LB is not available for use while the active LB is active. To determine the maximum number of load balancers per Edge Cluster, multiply the maximum number of LBs for the Edge Node type by the number of Edge Nodes and divide by 2. For example, with 10 Edge VM Large nodes in an Edge Cluster, you can have up to 200 small LB instances (40 x 10 / 2), or up to 20 medium LB instances (4 x 10 / 2).
* <%= vars.product_short %> deploys a virtual server for each load balancer instance. For service of type load balancer, it is one virtual server per service. There are two global virtual servers deployed for ingress resources (HTTP and HTTPS). And there is one global virtual server for the PKS API. For more information, see <a href="network-profiles-define.html">Defining Network Profiles</a>.

###<a id='nsx-install-vib'></a> Step 4: Enable VIB Repository Service

The VIB repository service provides access to native libraries for NSX Transport Nodes. VIB must be enabled before you proceed further with deploying NSX. 

For instructions, see [Enable Repository Service on NSX Manager](./nsxt-deploy.html#enable-repo).

<p class="note"><strong>NOTE:</strong> You must repeat this step for each NSX Manager VM.</p>

###<a id='nsx-install-tep'></a> Step 5: Create TEP IP Pool

Create Tunnel Endpoint IP Pool (TEP IP Pool) within the usable range of the **VTEP CIDR** that you defined in preparation for installing NSX-T. The TEP IP Pool is used for NSX Transport Nodes. 

For instructions, see [Create an IP Pool for Tunnel Endpoint IP Addresses](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-E7F7322D-D09B-481A-BD56-F1270D7C9692.html).

###<a id='nsx-instally-tzs'></a> Step 6: Create Overlay and VLAN Transport Zones

Create two [Transport Zones](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-7EA5F174-9D29-45DF-BDE8-94EAE57F9B62.html):

- A Overlay Transport Zone (named `TZ-Overlay`, for example) for use with <%= vars.product_short %> Control Plane services and Kubernetes Cluster deployment overlay networks. 
- A VLAN Transport Zone (named `TZ-VLAN`, for example) for NSX Edge uplinks (ingress/egress) for <%= vars.product_short %>-managed Kubernetes clusters. 

For instructions, see [Create Overlay and VLAN Transport Zones](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-F739DC79-4358-49F4-9C58-812475F33A66.html).

###<a id='nsx-install-uplink'></a> Step 7: Create an Uplink Profile for Edge Nodes

Create an NSX-T Uplink Profile for NSX Edge Nodes to be used with <%= vars.product_short %>. 

For instructions, see [Create an Uplink Profile](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-50FDFDFB-F660-4269-9503-39AE2BBA95B4.html).

###<a id='nsx-install-tns'></a> Step 8: Create Transport Edge Nodes

Create NSX Edge Transport Nodes to allow Edge Nodes to exchange traffic for virtual networks among other NSX nodes. 

For instructions, see [Create Edge Transport Nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-53295329-F02F-44D7-A6E0-2E3A9FAE6CF9.html).

###<a id='nsx-install-edge-cluster'></a> Step 9: Configure an Edge Cluster

Configure an [NSX Edge Cluster](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-898099FC-4ED2-4553-809D-B81B494B67E7.html) and add each NSX Edge Transport Node to the Edge Cluster. 

For instructions, see [Create an NSX Edge Cluster](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.4/installation/GUID-898099FC-4ED2-4553-809D-B81B494B67E7.html).

###<a id='nsx-install-edge-ha'></a> Step 10: Configure NSX Edge Nodes for HA

Configure NSX Edge Nodes for high availability (HA) using Active/Standby mode to support failover, as shown in the following figure. 

![NSX Edge High Availability](images/vsphere/nsxt-edge-ha.png)

For instructions, see [Configure Edge HA](nsxt-deploy.html#configure-edge-ha).

<p class="note"><strong>Note</strong>: If the T0 Router is not configured for HA as decribed in <a href="nsxt-deploy.html#create-edge-ha">Configure Edge Nodes for HA</a>, failover to the standby Edge Node will not occur.</p>

###<a id='nsx-install-esxi'></a> Step 11: Prepare ESXi Hosts for <%= vars.product_short %> Compute Plane

An [NSX Transport Node](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/2.3/com.vmware.nsxt.install.doc/GUID-FCC5390E-3489-47E8-ABE6-2F7FD43775BD.html) allows NSX Nodes to exchange traffic for virtual networks. ESXi hosts dedicated to the <%= vars.product_short %> Compute Cluster must be prepared as transport nodes. For instructions, see [Prepare Compute Cluster ESXi Hosts](nsxt-deploy.html#prepare-esxi).

<p class="note"><strong>Note</strong>: The Transport Nodes must be placed on free host NICs not already used by other vSwitches on the ESXi host. Use the <code>VTEPS</code> IP pool that allows ESXi hosts to route and communicate with each other, as well as other Edge Transport Nodes.</p>

For instructions, see [Prepare ESXi Hosts as Transport Nodes for NSX-T](./nsxt-deploy.html#prepare-esxi).