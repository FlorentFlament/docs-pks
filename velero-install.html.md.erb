---
title: Installing Minio, Valero, and Restic
owner: TKGI
---

This topic describes how to install Minio, Valero and Restic for the purposes of backing up and restoring Kubernetes workloads.

##<a id="prereqs"></a> Prerequisites

Read the [workload backup and restore requirements](./backup-and-restore-work.html#requirements) before proceeding.

Prepare a Linxu VM with sufficient storage to store several workload backups. You will install [Minio](https://velero.io/docs/main/contributions/minio/) on this VM.

It is assumed that you have TKGI Client VM (Linux) where CLI tools are installed, such as the TKGI CLI, Kubectl, and others. You will install the Velero CLI on this client VM. If you do not have such a VM, you can install the Velero CLI on your laptop, but you will need to adjust the installation steps accordingly.

It is assumed that the Kuberentes environment has internet access and can be reached by the client VM. If the environment has no internet access, refer to the [Velero air-gapped deployment](https://github.com/vmware-tanzu/velero/releases/tag/v1.4.2) documentation.

##<a id="minio-deploy"></a> Deploy Minio

Restic requires an object store as the backup destination for for workload backups. Complete the following tasks to install and configure Minio as the backend object store. The instructions descrige how to deploy the Minio Server on a Linux Ubuntu VM. For more informaion, see the [Minio quick start guide](https://docs.min.io/docs/minio-quickstart-guide.html). 

### <a id='minio-install'></a> Install Minio

```
wget https://dl.min.io/server/minio/release/linux-amd64/minio
```

```
chmod +x minio
```

Create directory where Minio data will be stored:

```
mkdir /DATA-MINIO
```

### <a id='minio-start'></a> Start Minio

Start the Minio server:

```
./minio server /DATA-MINIO
```

Once the Minio server is started, you are provided with the endpoint URL, AccessKey, and ScretKey for the data store instance. Record this information.

In addition, URLs are provided. Browse to the Minio data store using one of the URLs, for example <http://http://10.199.17.63:9000/minio/login/>.

  <img src="images/backup-restore/minio-01.png" alt="Minio Data Store" width="538">

Provide the AccessKey and ScretKey and log in.

  <img src="images/backup-restore/minio-02.png" alt="Minio Log In" width="538">

### <a id='minio-service'></a> Enable Minio as a Service

Configure Minio for automatic startup.

Download the `minio.service` script:

```
curl -O https://raw.githubusercontent.com/minio/minio-service/master/linux-systemd/minio.service
```

Edit the `minio.service` script and add the following value for `ExecStart`:

```
ExecStart=/usr/local/bin/minio server /DATA-MINIO path
```

Run the following series of commands to configure the Minio service:

```
cp minio.service /etc/systemd/system
cp minio /usr/local/bin/
systemctl daemon-reload
systemctl start  minio
systemctl status minio
systemctl enable minio
```

### <a id='minio-create'></a> Create Minio Bucket

Create a Minio bucket for TKGI workload backup and restore:

1. Launch the Mino browswer and log in to your object store.
1. Click the **Create bucket** icon.
1. Enter the bucket name, for example: `tkgi-velero`
1. Verify that the bucket is created.

  <img src="images/backup-restore/minio-03.png" alt="Minio Create Bucket" width="538">
  <img src="images/backup-restore/minio-04.png" alt="Minio Bucket Name" width="538">
  <img src="images/backup-restore/minio-05.png" alt="Verify Minio Bucket" width="538">

### <a id='minio-config'></a> Configure Minio Bucket

By default, the policy for the new `tkgi-velero` bucket is read-only. Change it to read-write:

1. Select the bucket and click on the dots link.
1. Select **Edit Policy**.
1. Change the policy to **Read and Write**.
1. Click **Add**.
1. Click the X button to close the dialog box.

  <img src="images/backup-restore/minio-06.png" alt="Minio Name Bucket" width="538">
  <img src="images/backup-restore/minio-07.png" alt="Minio Name Bucket" width="538">
  <img src="images/backup-restore/minio-08.png" alt="Minio Name Bucket" width="538">

##<a id="valero-deploy"></a> Deploy Valero with Restic

Install the Valero CLI and create the Valero and Restic pods. These instructions 

### <a id='valero-download'></a> Download Velero

Run the following commands on the TKGI client VM or local client to download Valero.

Create a directory.

```
mkdir /DATA/BINARIES/VELERO/1-4-2
```

CD to the directory.

```
cd /DATA/BINARIES/VELERO/1-4-2
```

Verify the directory.

```
pwd

/DATA/BINARIES/VELERO/1-4-2 
```

Download Valero:

```
wget https://github.com/vmware-tanzu/velero/releases/download/v1.4.2/velero-v1.4.2-linux-amd64.tar.gz
```

Verify: download:

```
ls
velero-v1.4.2-linux-amd64.tar.gz
```

Unzip the file:

```
gunzip velero-v1.4.2-linux-amd64.tar.gz
```
Untar the file:

```
tar xvf velero-v1.4.2-linux-amd64.tar
```

Verify that the CLI and Valero package are present:

```
ls

velero-v1.4.2-linux-amd64  velero-v1.4.2-linux-amd64.tar
```

### <a id='valero-cli-install'></a> Install the Velero CLI

Install Velero on TKIG client or on your local machine.

CD to the Velero CLI download.

```
cd velero-v1.4.2-linux-amd64/
```

Check for the binary:

```
ls

examples  LICENSE  velero
```

Copy the CLI to /usr/local/bin.

```
cp velero /usr/local/bin/velero
```

Verify installation:

```
velero version

Client:
    Version: v1.4.2
    Git commit: 56a08a4d695d893f0863f697c2f926e27d70c0c5
```

### <a id='valero-cluster-install'></a> Install Velero and Restic on the Target Kubernetes Cluster

Install the Valero and Restic pods on each Kubernetes cluster whose workloads you want to backup. The instructions for installaing Valero and Restic depend on the type of object store. The following instructions assume the use of [Minio](./velero-install.html#minio-deploy) and that the Kubernetes cluster has internet access. If you are installing Velero on a cluster in an air-gapped environment, see [Air-gapped deployments](https://velero.io/docs/v1.4/on-premises/#air-gapped-deployments) in the Velero documentation.

#### Prerequisites

Before installing Valero and Restic on the Kubernetes cluster:

- Get the name of the Minio bucket; it is `tkgi-valero` in our example
- Get the keys for the Minio bucket: 
  - AccessKey: `0XXNO8JCCGV41QZBV0RQ` (for example)
  - SecretKey: SecretKey: `clZ1bf8Ljkvkmq7fHucrKCkxV39BRbcycGeXQDfx` (for example)
- Make sure `kubectl` works against the cluster (use `tkgi get-credentials` if needed)

#### Procedure

Create the `credentials-minio` with credentials to access the Minio server.

```
CD /DATA/BINARIES/VELERO/1-4-2/velero-v1.4.2-linux-amd64

vi credentials-minio

aws_access_key_id = 0XXNO8JCCGV41QZBV0RQ

aws_secret_access_key = clZ1bf8Ljkvkmq7fHucrKCkxV39BRbcycGeXQDfx
```

Verify:

```
ls

credentials-minio  examples  LICENSE  velero
```

Run the following command to install Valero on the Kubernetes cluster:

```
    velero install  \
    --provider aws \
    --plugins velero/velero-plugin-for-aws:v1.0.0 \
    --bucket tkgi-velero \
    --secret-file ./credentials-minio \
    --use-volume-snapshots=false \
    --use-restic \
    --backup-location-config \
    region=minio,s3ForcePathStyle="true",s3Url=http://10.199.17.63:9000,publicUrl=http://10.199.17.63:9000
```

For example:


```
#     velero install  \
>     --provider aws \
>     --plugins velero/velero-plugin-for-aws:v1.0.0 \
>     --bucket tkgi-velero \
>     --secret-file ./credentials-minio \
>     --use-volume-snapshots=false \
>     --use-restic \
>     --backup-location-config \
>     region=minio,s3ForcePathStyle="true",s3Url=http://10.199.17.63:9000,publicUrl=http://10.199.17.63:9000
```

Sample expected result:

```
CustomResourceDefinition/backups.velero.io: attempting to create resource
CustomResourceDefinition/backups.velero.io: created
...
Waiting for resources to be ready in cluster...
...
Deployment/velero: attempting to create resource
Deployment/velero: created
DaemonSet/restic: attempting to create resource
DaemonSet/restic: created
Velero is installed! Use 'kubectl logs deployment/velero -n velero' to view the status.
```

Verify the installation of Valero and Restic:

```
kubectl logs deployment/velero -n velero

time="2020-07-21T21:05:53Z" level=info msg="setting log-level to INFO" logSource="pkg/cmd/server/server.go:177"
time="2020-07-21T21:05:53Z" level=info msg="Starting Velero server v1.4.2 (56a08a4d695d893f0863f697c2f926e27d70c0c5)" logSource="pkg/cmd/server/server.go:179"
time="2020-07-21T21:05:53Z" level=info msg="1 feature flags enabled []" logSource="pkg/cmd/server/server.go:181"
...
time="2020-07-21T21:05:59Z" level=info msg="Starting controller" controller=gc-controller logSource="pkg/controller/generic_controller.go:76"
time="2020-07-21T21:05:59Z" level=info msg="Starting controller" controller=backup logSource="pkg/controller/generic_controller.go:76"
time="2020-07-21T21:05:59Z" level=info msg="Done checking for expired DeleteBackupRequests" controller=backup-deletion logSource="pkg/controller/backup_deletion_controller.go:579"
```

Verify the `velero` namespace.

```
kubectl get ns

NAME              STATUS   AGE
default           Active   13d
kube-node-lease   Active   13d
kube-public       Active   13d
kube-system       Active   13d
pks-system        Active   13d
velero            Active   2m38s
```

#### Enable Privileged Mode and Modify the Host Path

To run the 3-pod Restic DaemonSet on a Kubernetes cluster in TKGI, you must modify the Restic DaemonSet spec. For more information as to why, see the [Restic documentation](https://velero.io/docs/v1.1.0/restic/). In addition, the hostPath should be changed from `/var/lib/kubelet/pods` to `/var/vcap/data/kubelet/pods`. The instructions for both of these configurations are provided below.

In addition, you must enable the **Allow Privileged** option in your plan configuration so that Restic is able to mount the `hostPath`. See [Plan Configuration](./installing-nsx-t.html#plans) in the TKGI documentation for details. If you change the plan, you will need to redeploy the cluster. Note that Because you are allowing privileged containers in the cluster, you should apply PSP to control pod access. See [Enabling Pod Security Policy](./pod-security-policy.html). 

Verify the 3-pod Restic DaemonSet: 

```
kubectl get pod -n velero

NAME                          READY   STATUS             RESTARTS   AGE
pod/restic-p5bdz              0/1     CrashLoopBackOff   4          3m8s
pod/restic-rbmnd              0/1     CrashLoopBackOff   4          3m8s
pod/restic-vcpjm              0/1     CrashLoopBackOff   4          3m8s
pod/velero-68f47744f5-lb5df   1/1     Running            0          3m8s
```

Run the following command:

```
kubectl edit daemonset restic -n velero
```

Change hostPath from `/var/lib/kubelet/pods` to `/var/vcap/data/kubelet/pods`:

```
     - hostPath:

          path: /var/vcap/data/kubelet/pods
```

Save the file.

Verify the 3-pod Restic DaemonSet: 

```
kubectl get pod -n velero

NAME                      READY   STATUS    RESTARTS   AGE
restic-5jln8              1/1     Running   0          73s
restic-bpvtq              1/1     Running   0          73s
restic-vg8j7              1/1     Running   0          73s
velero-68f47744f5-lb5df   1/1     Running   0          10m
```
##<a id="valero-memory"></a> Configure Velero Memory Limits (If Necessary)

By default Velero sets limits and request memory at 256 and 128 by default. In case a Velero backup get status='InProgress' for many hours, increase these limits.

```
kubectl edit deployment/velero -n velero 
```

Change limits and request memory to 512 and 256.

  <img src="images/backup-restore/velero-limits.png" alt="Velero Limits" width="538">

